{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1WlNbIXlLfED",
        "d0Z444TPALeF",
        "H0n451O5DMNe",
        "VSU2MGLYc73x",
        "tIX_Z_9aWTWu",
        "zieY81s8cUHA",
        "TxKRhGXveJcw",
        "Crly41xJaNBY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Dataset"
      ],
      "metadata": {
        "id": "1WlNbIXlLfED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import itertools\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# importing data from AutoSleep App\n",
        "df = pd.read_csv('AutoSleep-20210330-to-20240114.csv')"
      ],
      "metadata": {
        "id": "VvHZ9Yn-LhAU"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning and Preprocessing"
      ],
      "metadata": {
        "id": "d0Z444TPALeF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RCRkbDkD9whm",
        "outputId": "a6d47a14-ca4a-42b7-d152-d896ec838c93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  fromDate                 toDate              bedtime  \\\n",
              "0  Wednesday, Mar 31, 2021  Thursday, Apr 1, 2021  2021-04-01 12:15:00   \n",
              "1    Thursday, Apr 1, 2021    Friday, Apr 2, 2021  2021-04-02 12:45:00   \n",
              "2      Friday, Apr 2, 2021  Saturday, Apr 3, 2021  2021-04-03 11:04:23   \n",
              "3    Saturday, Apr 3, 2021    Sunday, Apr 4, 2021  2021-04-04 12:08:15   \n",
              "4      Sunday, Apr 4, 2021    Monday, Apr 5, 2021  2021-04-05 11:18:41   \n",
              "\n",
              "              waketime     inBed     awake fellAsleepIn    asleep asleepAvg7  \\\n",
              "0  2021-04-01 19:26:00  07:11:00  00:05:00     00:00:00  07:06:00   07:06:00   \n",
              "1  2021-04-02 20:15:00  07:30:00  00:00:00     00:00:00  07:30:00   07:18:00   \n",
              "2  2021-04-03 19:54:00  08:49:36  00:22:36     00:11:37  08:27:00   07:41:00   \n",
              "3  2021-04-04 22:04:00  09:55:44  00:03:44     00:03:45  09:52:00   08:13:45   \n",
              "4  2021-04-05 18:54:00  07:35:18  01:09:18     00:49:19  06:26:00   07:52:12   \n",
              "\n",
              "   efficiency  efficiencyAvg7   quality qualityAvg7      deep  deepAvg7  \\\n",
              "0        98.8            98.8  05:32:47    05:32:47  04:28:13  04:28:13   \n",
              "1       100.0            99.4  05:56:02    05:44:24  04:15:00  04:21:36   \n",
              "2        95.7            98.2  07:24:53    06:17:54  03:50:27  04:11:13   \n",
              "3        99.4            98.5  08:44:39    06:54:35  05:03:35  04:24:18   \n",
              "4        84.8            95.7  06:03:48    06:44:26  04:17:20  04:22:55   \n",
              "\n",
              "   sleepBPM  sleepBPMAvg7  wakingBPM  wakingBPMAvg7    hrv  hrvAvg7  sleepHRV  \\\n",
              "0      45.7          45.7       53.0           53.0  112.0    112.0      55.0   \n",
              "1      46.8          46.3       46.0           49.5  153.0    132.0      61.0   \n",
              "2      45.7          46.1       45.0           48.0  130.0    131.0      76.0   \n",
              "3      45.5          45.9       46.0           47.5   86.0    120.0      58.0   \n",
              "4      45.6          45.9       43.0           46.6   76.0    111.0      59.0   \n",
              "\n",
              "   sleepHRVAvg7  respAvg  respMin  respMax  \n",
              "0          98.0      NaN      NaN      NaN  \n",
              "1          82.0      NaN      NaN      NaN  \n",
              "2          85.0      NaN      NaN      NaN  \n",
              "3          76.0      NaN      NaN      NaN  \n",
              "4          65.0      NaN      NaN      NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82ba3689-195b-4fb2-ab69-3639dd8d5eb0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fromDate</th>\n",
              "      <th>toDate</th>\n",
              "      <th>bedtime</th>\n",
              "      <th>waketime</th>\n",
              "      <th>inBed</th>\n",
              "      <th>awake</th>\n",
              "      <th>fellAsleepIn</th>\n",
              "      <th>asleep</th>\n",
              "      <th>asleepAvg7</th>\n",
              "      <th>efficiency</th>\n",
              "      <th>efficiencyAvg7</th>\n",
              "      <th>quality</th>\n",
              "      <th>qualityAvg7</th>\n",
              "      <th>deep</th>\n",
              "      <th>deepAvg7</th>\n",
              "      <th>sleepBPM</th>\n",
              "      <th>sleepBPMAvg7</th>\n",
              "      <th>wakingBPM</th>\n",
              "      <th>wakingBPMAvg7</th>\n",
              "      <th>hrv</th>\n",
              "      <th>hrvAvg7</th>\n",
              "      <th>sleepHRV</th>\n",
              "      <th>sleepHRVAvg7</th>\n",
              "      <th>respAvg</th>\n",
              "      <th>respMin</th>\n",
              "      <th>respMax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wednesday, Mar 31, 2021</td>\n",
              "      <td>Thursday, Apr 1, 2021</td>\n",
              "      <td>2021-04-01 12:15:00</td>\n",
              "      <td>2021-04-01 19:26:00</td>\n",
              "      <td>07:11:00</td>\n",
              "      <td>00:05:00</td>\n",
              "      <td>00:00:00</td>\n",
              "      <td>07:06:00</td>\n",
              "      <td>07:06:00</td>\n",
              "      <td>98.8</td>\n",
              "      <td>98.8</td>\n",
              "      <td>05:32:47</td>\n",
              "      <td>05:32:47</td>\n",
              "      <td>04:28:13</td>\n",
              "      <td>04:28:13</td>\n",
              "      <td>45.7</td>\n",
              "      <td>45.7</td>\n",
              "      <td>53.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Thursday, Apr 1, 2021</td>\n",
              "      <td>Friday, Apr 2, 2021</td>\n",
              "      <td>2021-04-02 12:45:00</td>\n",
              "      <td>2021-04-02 20:15:00</td>\n",
              "      <td>07:30:00</td>\n",
              "      <td>00:00:00</td>\n",
              "      <td>00:00:00</td>\n",
              "      <td>07:30:00</td>\n",
              "      <td>07:18:00</td>\n",
              "      <td>100.0</td>\n",
              "      <td>99.4</td>\n",
              "      <td>05:56:02</td>\n",
              "      <td>05:44:24</td>\n",
              "      <td>04:15:00</td>\n",
              "      <td>04:21:36</td>\n",
              "      <td>46.8</td>\n",
              "      <td>46.3</td>\n",
              "      <td>46.0</td>\n",
              "      <td>49.5</td>\n",
              "      <td>153.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Friday, Apr 2, 2021</td>\n",
              "      <td>Saturday, Apr 3, 2021</td>\n",
              "      <td>2021-04-03 11:04:23</td>\n",
              "      <td>2021-04-03 19:54:00</td>\n",
              "      <td>08:49:36</td>\n",
              "      <td>00:22:36</td>\n",
              "      <td>00:11:37</td>\n",
              "      <td>08:27:00</td>\n",
              "      <td>07:41:00</td>\n",
              "      <td>95.7</td>\n",
              "      <td>98.2</td>\n",
              "      <td>07:24:53</td>\n",
              "      <td>06:17:54</td>\n",
              "      <td>03:50:27</td>\n",
              "      <td>04:11:13</td>\n",
              "      <td>45.7</td>\n",
              "      <td>46.1</td>\n",
              "      <td>45.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Saturday, Apr 3, 2021</td>\n",
              "      <td>Sunday, Apr 4, 2021</td>\n",
              "      <td>2021-04-04 12:08:15</td>\n",
              "      <td>2021-04-04 22:04:00</td>\n",
              "      <td>09:55:44</td>\n",
              "      <td>00:03:44</td>\n",
              "      <td>00:03:45</td>\n",
              "      <td>09:52:00</td>\n",
              "      <td>08:13:45</td>\n",
              "      <td>99.4</td>\n",
              "      <td>98.5</td>\n",
              "      <td>08:44:39</td>\n",
              "      <td>06:54:35</td>\n",
              "      <td>05:03:35</td>\n",
              "      <td>04:24:18</td>\n",
              "      <td>45.5</td>\n",
              "      <td>45.9</td>\n",
              "      <td>46.0</td>\n",
              "      <td>47.5</td>\n",
              "      <td>86.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sunday, Apr 4, 2021</td>\n",
              "      <td>Monday, Apr 5, 2021</td>\n",
              "      <td>2021-04-05 11:18:41</td>\n",
              "      <td>2021-04-05 18:54:00</td>\n",
              "      <td>07:35:18</td>\n",
              "      <td>01:09:18</td>\n",
              "      <td>00:49:19</td>\n",
              "      <td>06:26:00</td>\n",
              "      <td>07:52:12</td>\n",
              "      <td>84.8</td>\n",
              "      <td>95.7</td>\n",
              "      <td>06:03:48</td>\n",
              "      <td>06:44:26</td>\n",
              "      <td>04:17:20</td>\n",
              "      <td>04:22:55</td>\n",
              "      <td>45.6</td>\n",
              "      <td>45.9</td>\n",
              "      <td>43.0</td>\n",
              "      <td>46.6</td>\n",
              "      <td>76.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82ba3689-195b-4fb2-ab69-3639dd8d5eb0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82ba3689-195b-4fb2-ab69-3639dd8d5eb0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82ba3689-195b-4fb2-ab69-3639dd8d5eb0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7be097ca-8030-4595-bbba-d02a33c3080e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7be097ca-8030-4595-bbba-d02a33c3080e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7be097ca-8030-4595-bbba-d02a33c3080e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "# Delete the first column\n",
        "df = df.iloc[:, 1:]\n",
        "\n",
        "# Delete all columns with full of Na\n",
        "df = df.dropna(axis=1, how='all')\n",
        "\n",
        "df = df.drop('sessions', axis=1)\n",
        "df = df.drop('dayBPM', axis=1)\n",
        "df = df.drop('dayBPMAvg7', axis=1)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see that we have these variables, Because of the limited capabilities of my wearable, the only fields I was able to record were the following:\n",
        "*   From Date/To Date: the date the sleep session was recorded in\n",
        "*   Bedtime / Waketime: the time you went to bed and awoke.\n",
        "*   InBed: how long you were in bed for, shown in hours, minutes and seconds\n",
        "*   Awake: how long you were awake for, shown in hours, minutes and seconds\n",
        "*   Fell Asleep: the amount time it took you to fall asleep\n",
        "*   Asleep / AsleepAvg7: the sleep duration recorded along with the 7 day sleep duration average on that date\n",
        "*   Efficiency / EfficiencyAvg7: the ratio of time asleep versus time spent in bed along with the 7 day efficiency average\n",
        "*   Quality / QualityAvg7: quality considers how long you have slept, how restless you've been and your sleeping heart rate. It is shown as hours, minutes and seconds along with a 7 day sleep quality average\n",
        "*   Deep / DeepAvg7: where your heart rate slows and your muscles relax to a point where you barely move. It is shown as hours, minutes and seconds along with a 7 day deep sleep average\n",
        "*   SleepBPM / SleepBPMAvg7: your average heart rate shown in beats per minute for the sleep, along with a 7 day average of your sleeping heart rate\n",
        "*   DayBPM / DayBPMAvg7: your average heart rate outside of your sleep, generally during the day for most users, shown in beats per minute, along with a 7 day average of your daily heart rate\n",
        "*   WakingBPM / WakingBPMAvg7: your waking pulse shown in beats per minute which is automatically captured by AutoSleep , along with a 7 day waking pulse average\n",
        "*   HRV / HRVAvg7: your Heart Rate Variability. AutoSleep will use the maximum value where multiple values exist for the same date. This will also show a 7 day average of your HRV\n",
        "*   sleepHRV / sleepHRVAvg7: your sleep Heart Rate Variability.\n",
        "*   respAvg / respMin /\trespMax: Average, minimum and maximum respiration"
      ],
      "metadata": {
        "id": "0A3GlVkeLknx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next the data in the form of hour:minute:second in OBJECT format needs to be converted to minute data in FLOAT format to facilitate further exploratory data analysis or building machine learning models."
      ],
      "metadata": {
        "id": "R1UZVuq7DaQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns that need to be converted from hh:mm:ss to float64\n",
        "time_columns = ['inBed', 'awake', 'fellAsleepIn', 'asleep', 'asleepAvg7', 'quality', 'qualityAvg7', 'deep', 'deepAvg7']\n",
        "\n",
        "# Function to convert time string to minutes\n",
        "def time_to_minutes(time_str):\n",
        "    if pd.isna(time_str) or isinstance(time_str, float):\n",
        "        return time_str\n",
        "    hours, minutes, seconds = map(int, time_str.split(':'))\n",
        "    return hours * 60 + minutes + seconds / 60\n",
        "\n",
        "# Convert the time data to minutes\n",
        "for col in time_columns:\n",
        "    df[col] = df[col].apply(time_to_minutes)"
      ],
      "metadata": {
        "id": "L8rjKeuf0Q4Z"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H0n451O5DMNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract week, month, day data from fromdate"
      ],
      "metadata": {
        "id": "K6AjkXlIaLva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "df['fromDate'] = pd.to_datetime(df['fromDate'])\n",
        "\n",
        "df['toDate'] = pd.to_datetime(df['toDate'])\n",
        "\n",
        "df['day_of_week'] = df['fromDate'].dt.day_name()\n",
        "\n",
        "df['Week'] = df['fromDate'].dt.weekday\n",
        "\n",
        "df['Month'] = df['fromDate'].dt.month\n",
        "\n",
        "df['Day'] = df['fromDate'].dt.day"
      ],
      "metadata": {
        "id": "xWdR2IyxhTuN"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['bedtime'] = pd.to_datetime(df['bedtime']).dt.strftime(\"%H:%M:%S\")\n",
        "df['waketime'] = pd.to_datetime(df['waketime']).dt.strftime(\"%H:%M:%S\")"
      ],
      "metadata": {
        "id": "DnnXKC5xcMDJ"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time_to_float(time_str):\n",
        "    time = pd.to_datetime(time_str, format='%H:%M:%S')\n",
        "    return time.hour * 60 + time.minute + time.second / 60\n",
        "\n",
        "# convert form datetime to float\n",
        "df['bedtime_float'] = df['bedtime'].apply(time_to_float)\n",
        "df['waketime_float'] = df['waketime'].apply(time_to_float)"
      ],
      "metadata": {
        "id": "2m2j-v7xghmo"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the day_of_week column, which includes all days of the week, to one-hot encoded format"
      ],
      "metadata": {
        "id": "oRFNUWDCS1Nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, columns=['day_of_week'])"
      ],
      "metadata": {
        "id": "EEMHA-cLSz4m"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lag_features = ['asleepAvg7', 'efficiencyAvg7', 'qualityAvg7', 'deepAvg7', 'sleepBPMAvg7', 'hrvAvg7', 'sleepHRVAvg7']\n",
        "for feature in lag_features:\n",
        "    df[feature + '_lag'] = df[feature].shift(1)"
      ],
      "metadata": {
        "id": "skJ6e4DrgpdD"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because of the limitations of the record, I have only 400 or so entries that are non-null data that contain respiratory information, and 600 or so entries that are non-null data that do not contain respiratory information, and I keep both parts of the data."
      ],
      "metadata": {
        "id": "3hhjrwwPDwbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split the data to df1 and df2\n",
        "#df1 is data that without any NA\n",
        "df1 = df.drop(df.columns[-13:-10], axis=1)\n",
        "df1 = df1.dropna()\n",
        "#df_resp is data that with only 400+ data but has columns 'resp'\n",
        "df_resp = df.dropna()"
      ],
      "metadata": {
        "id": "3qscAXtFCqKe"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resp.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uPaVoiVxaVW6",
        "outputId": "91d7f181-2823-421b-b5de-16cb2569b9ae"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fromDate     toDate   bedtime  waketime       inBed      awake  \\\n",
              "159 2021-09-22 2021-09-23  10:43:40  17:46:00  422.316667  20.316667   \n",
              "160 2021-09-23 2021-09-24  11:44:12  18:00:00  375.783333  62.783333   \n",
              "161 2021-09-24 2021-09-25  11:12:29  19:47:00  514.500000  60.500000   \n",
              "162 2021-09-25 2021-09-26  11:15:48  18:59:00  494.183333  51.183333   \n",
              "163 2021-09-26 2021-09-27  11:04:58  18:45:00  460.016667  82.016667   \n",
              "\n",
              "     fellAsleepIn  asleep  asleepAvg7  efficiency  efficiencyAvg7     quality  \\\n",
              "159      1.333333   402.0  453.700000        95.2            88.0  336.333333   \n",
              "160     61.783333   313.0  446.850000        83.3            90.9  269.883333   \n",
              "161     33.516667   454.0  445.283333        88.2            89.2  371.116667   \n",
              "162     51.200000   443.0  434.283333        88.9            87.9  361.033333   \n",
              "163     70.033333   378.0  410.416667        82.2            85.4  313.833333   \n",
              "\n",
              "     qualityAvg7    deep    deepAvg7  sleepBPM  sleepBPMAvg7  wakingBPM  \\\n",
              "159   378.666667  139.15  182.700000      53.3          50.7       52.0   \n",
              "160   371.850000  140.85  178.166667      49.5          50.8       50.0   \n",
              "161   369.883333  181.60  177.533333      49.0          50.7       51.0   \n",
              "162   366.083333  174.30  182.166667      47.9          50.3       46.0   \n",
              "163   344.566667  151.20  168.750000      46.7          48.9       46.0   \n",
              "\n",
              "     wakingBPMAvg7    hrv  hrvAvg7  sleepHRV  sleepHRVAvg7  respAvg  respMin  \\\n",
              "159           50.9   73.0     94.0      62.0          70.0     17.2     14.5   \n",
              "160           50.0  131.0     99.0      82.0          72.0     17.9     16.5   \n",
              "161           50.6  105.0    104.0      79.0          76.0     16.9     14.0   \n",
              "162           50.1  137.0    103.0      71.0          75.0     17.1     15.0   \n",
              "163           49.0  321.0    137.0     116.0          80.0     17.4     16.5   \n",
              "\n",
              "     respMax  Week  Month  Day  bedtime_float  waketime_float  \\\n",
              "159     23.0     2      9   22     643.666667          1066.0   \n",
              "160     19.5     3      9   23     704.200000          1080.0   \n",
              "161     20.5     4      9   24     672.483333          1187.0   \n",
              "162     19.0     5      9   25     675.800000          1139.0   \n",
              "163     21.0     6      9   26     664.966667          1125.0   \n",
              "\n",
              "     day_of_week_Friday  day_of_week_Monday  day_of_week_Saturday  \\\n",
              "159                   0                   0                     0   \n",
              "160                   0                   0                     0   \n",
              "161                   1                   0                     0   \n",
              "162                   0                   0                     1   \n",
              "163                   0                   0                     0   \n",
              "\n",
              "     day_of_week_Sunday  day_of_week_Thursday  day_of_week_Tuesday  \\\n",
              "159                   0                     0                    0   \n",
              "160                   0                     1                    0   \n",
              "161                   0                     0                    0   \n",
              "162                   0                     0                    0   \n",
              "163                   1                     0                    0   \n",
              "\n",
              "     day_of_week_Wednesday  asleepAvg7_lag  efficiencyAvg7_lag  \\\n",
              "159                      1      456.700000                87.9   \n",
              "160                      0      453.700000                88.0   \n",
              "161                      0      446.850000                90.9   \n",
              "162                      0      445.283333                89.2   \n",
              "163                      0      434.283333                87.9   \n",
              "\n",
              "     qualityAvg7_lag  deepAvg7_lag  sleepBPMAvg7_lag  hrvAvg7_lag  \\\n",
              "159       381.183333    187.450000              49.9         95.0   \n",
              "160       378.666667    182.700000              50.7         94.0   \n",
              "161       371.850000    178.166667              50.8         99.0   \n",
              "162       369.883333    177.533333              50.7        104.0   \n",
              "163       366.083333    182.166667              50.3        103.0   \n",
              "\n",
              "     sleepHRVAvg7_lag  \n",
              "159              69.0  \n",
              "160              70.0  \n",
              "161              72.0  \n",
              "162              76.0  \n",
              "163              75.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31958bef-0a27-4378-8ef0-07018b698d0a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fromDate</th>\n",
              "      <th>toDate</th>\n",
              "      <th>bedtime</th>\n",
              "      <th>waketime</th>\n",
              "      <th>inBed</th>\n",
              "      <th>awake</th>\n",
              "      <th>fellAsleepIn</th>\n",
              "      <th>asleep</th>\n",
              "      <th>asleepAvg7</th>\n",
              "      <th>efficiency</th>\n",
              "      <th>efficiencyAvg7</th>\n",
              "      <th>quality</th>\n",
              "      <th>qualityAvg7</th>\n",
              "      <th>deep</th>\n",
              "      <th>deepAvg7</th>\n",
              "      <th>sleepBPM</th>\n",
              "      <th>sleepBPMAvg7</th>\n",
              "      <th>wakingBPM</th>\n",
              "      <th>wakingBPMAvg7</th>\n",
              "      <th>hrv</th>\n",
              "      <th>hrvAvg7</th>\n",
              "      <th>sleepHRV</th>\n",
              "      <th>sleepHRVAvg7</th>\n",
              "      <th>respAvg</th>\n",
              "      <th>respMin</th>\n",
              "      <th>respMax</th>\n",
              "      <th>Week</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>bedtime_float</th>\n",
              "      <th>waketime_float</th>\n",
              "      <th>day_of_week_Friday</th>\n",
              "      <th>day_of_week_Monday</th>\n",
              "      <th>day_of_week_Saturday</th>\n",
              "      <th>day_of_week_Sunday</th>\n",
              "      <th>day_of_week_Thursday</th>\n",
              "      <th>day_of_week_Tuesday</th>\n",
              "      <th>day_of_week_Wednesday</th>\n",
              "      <th>asleepAvg7_lag</th>\n",
              "      <th>efficiencyAvg7_lag</th>\n",
              "      <th>qualityAvg7_lag</th>\n",
              "      <th>deepAvg7_lag</th>\n",
              "      <th>sleepBPMAvg7_lag</th>\n",
              "      <th>hrvAvg7_lag</th>\n",
              "      <th>sleepHRVAvg7_lag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>2021-09-22</td>\n",
              "      <td>2021-09-23</td>\n",
              "      <td>10:43:40</td>\n",
              "      <td>17:46:00</td>\n",
              "      <td>422.316667</td>\n",
              "      <td>20.316667</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>402.0</td>\n",
              "      <td>453.700000</td>\n",
              "      <td>95.2</td>\n",
              "      <td>88.0</td>\n",
              "      <td>336.333333</td>\n",
              "      <td>378.666667</td>\n",
              "      <td>139.15</td>\n",
              "      <td>182.700000</td>\n",
              "      <td>53.3</td>\n",
              "      <td>50.7</td>\n",
              "      <td>52.0</td>\n",
              "      <td>50.9</td>\n",
              "      <td>73.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>17.2</td>\n",
              "      <td>14.5</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>22</td>\n",
              "      <td>643.666667</td>\n",
              "      <td>1066.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>456.700000</td>\n",
              "      <td>87.9</td>\n",
              "      <td>381.183333</td>\n",
              "      <td>187.450000</td>\n",
              "      <td>49.9</td>\n",
              "      <td>95.0</td>\n",
              "      <td>69.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>2021-09-23</td>\n",
              "      <td>2021-09-24</td>\n",
              "      <td>11:44:12</td>\n",
              "      <td>18:00:00</td>\n",
              "      <td>375.783333</td>\n",
              "      <td>62.783333</td>\n",
              "      <td>61.783333</td>\n",
              "      <td>313.0</td>\n",
              "      <td>446.850000</td>\n",
              "      <td>83.3</td>\n",
              "      <td>90.9</td>\n",
              "      <td>269.883333</td>\n",
              "      <td>371.850000</td>\n",
              "      <td>140.85</td>\n",
              "      <td>178.166667</td>\n",
              "      <td>49.5</td>\n",
              "      <td>50.8</td>\n",
              "      <td>50.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>17.9</td>\n",
              "      <td>16.5</td>\n",
              "      <td>19.5</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>704.200000</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>453.700000</td>\n",
              "      <td>88.0</td>\n",
              "      <td>378.666667</td>\n",
              "      <td>182.700000</td>\n",
              "      <td>50.7</td>\n",
              "      <td>94.0</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>2021-09-24</td>\n",
              "      <td>2021-09-25</td>\n",
              "      <td>11:12:29</td>\n",
              "      <td>19:47:00</td>\n",
              "      <td>514.500000</td>\n",
              "      <td>60.500000</td>\n",
              "      <td>33.516667</td>\n",
              "      <td>454.0</td>\n",
              "      <td>445.283333</td>\n",
              "      <td>88.2</td>\n",
              "      <td>89.2</td>\n",
              "      <td>371.116667</td>\n",
              "      <td>369.883333</td>\n",
              "      <td>181.60</td>\n",
              "      <td>177.533333</td>\n",
              "      <td>49.0</td>\n",
              "      <td>50.7</td>\n",
              "      <td>51.0</td>\n",
              "      <td>50.6</td>\n",
              "      <td>105.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>16.9</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.5</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>24</td>\n",
              "      <td>672.483333</td>\n",
              "      <td>1187.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>446.850000</td>\n",
              "      <td>90.9</td>\n",
              "      <td>371.850000</td>\n",
              "      <td>178.166667</td>\n",
              "      <td>50.8</td>\n",
              "      <td>99.0</td>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>2021-09-25</td>\n",
              "      <td>2021-09-26</td>\n",
              "      <td>11:15:48</td>\n",
              "      <td>18:59:00</td>\n",
              "      <td>494.183333</td>\n",
              "      <td>51.183333</td>\n",
              "      <td>51.200000</td>\n",
              "      <td>443.0</td>\n",
              "      <td>434.283333</td>\n",
              "      <td>88.9</td>\n",
              "      <td>87.9</td>\n",
              "      <td>361.033333</td>\n",
              "      <td>366.083333</td>\n",
              "      <td>174.30</td>\n",
              "      <td>182.166667</td>\n",
              "      <td>47.9</td>\n",
              "      <td>50.3</td>\n",
              "      <td>46.0</td>\n",
              "      <td>50.1</td>\n",
              "      <td>137.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>17.1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>25</td>\n",
              "      <td>675.800000</td>\n",
              "      <td>1139.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>445.283333</td>\n",
              "      <td>89.2</td>\n",
              "      <td>369.883333</td>\n",
              "      <td>177.533333</td>\n",
              "      <td>50.7</td>\n",
              "      <td>104.0</td>\n",
              "      <td>76.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>2021-09-26</td>\n",
              "      <td>2021-09-27</td>\n",
              "      <td>11:04:58</td>\n",
              "      <td>18:45:00</td>\n",
              "      <td>460.016667</td>\n",
              "      <td>82.016667</td>\n",
              "      <td>70.033333</td>\n",
              "      <td>378.0</td>\n",
              "      <td>410.416667</td>\n",
              "      <td>82.2</td>\n",
              "      <td>85.4</td>\n",
              "      <td>313.833333</td>\n",
              "      <td>344.566667</td>\n",
              "      <td>151.20</td>\n",
              "      <td>168.750000</td>\n",
              "      <td>46.7</td>\n",
              "      <td>48.9</td>\n",
              "      <td>46.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>321.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>17.4</td>\n",
              "      <td>16.5</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>26</td>\n",
              "      <td>664.966667</td>\n",
              "      <td>1125.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>434.283333</td>\n",
              "      <td>87.9</td>\n",
              "      <td>366.083333</td>\n",
              "      <td>182.166667</td>\n",
              "      <td>50.3</td>\n",
              "      <td>103.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31958bef-0a27-4378-8ef0-07018b698d0a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-31958bef-0a27-4378-8ef0-07018b698d0a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-31958bef-0a27-4378-8ef0-07018b698d0a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3dca237d-2225-482b-a69b-401ebbfdc696\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3dca237d-2225-482b-a69b-401ebbfdc696')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3dca237d-2225-482b-a69b-401ebbfdc696 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8LTvjcqcg49V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = df_resp[['bedtime_float', 'asleepAvg7_lag', 'efficiencyAvg7_lag', 'qualityAvg7_lag', 'deep', 'deepAvg7_lag', 'sleepBPMAvg7_lag', 'wakingBPM', 'wakingBPMAvg7', 'hrv', 'hrvAvg7_lag', 'sleepHRVAvg7_lag', 'respAvg', 'respMin', 'respMax', 'day_of_week_Friday','day_of_week_Monday','day_of_week_Saturday','day_of_week_Sunday','day_of_week_Thursday','day_of_week_Tuesday','day_of_week_Wednesday']]\n",
        "target = df_resp['waketime_float']\n",
        "\n",
        "X = features.values\n",
        "y = target.values\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "7nw5_qR8g1Vx"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP"
      ],
      "metadata": {
        "id": "VSU2MGLYc73x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert arrays to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Create Tensor datasets and data loaders\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "test_data = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
        "valid_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, dropout_rate=0.2):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Initialize the MLP\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MLP(input_size=X.shape[1])\n",
        "model = model.to(device)\n",
        "print(device)\n",
        "\n",
        "epoch_num = 500\n",
        "learning_rate = 0.006\n",
        "weight_decay = 1e-3\n",
        "\n",
        "def train_and_evaluate(model, train_loader, valid_loader, num_epochs = 20, learning_rate=0.01, weight_decay=0.0, patience = 5):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_maes = []\n",
        "\n",
        "    model.to(device)\n",
        "    # Define loss function\n",
        "    criterion = nn.MSELoss()\n",
        "    # Define optimizer with hyperparameters\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Early stopping initialization\n",
        "    the_last_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    best_epoch = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training loop\n",
        "        model.train()  # Set the model to training mode\n",
        "        total_train_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        total_val_loss = 0.0\n",
        "\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valid_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs.squeeze(), labels)\n",
        "                total_val_loss += loss.item() * inputs.size(0)\n",
        "                all_preds.extend(outputs.squeeze().cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(train_loader.dataset)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        mae = mean_absolute_error(all_labels, all_preds)\n",
        "        val_maes.append(mae)\n",
        "\n",
        "        # Print statistics\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
        "\n",
        "        # Early stopping and model checkpointing\n",
        "        if avg_val_loss < the_last_loss:\n",
        "            epochs_no_improve = 0\n",
        "            the_last_loss = avg_val_loss\n",
        "            best_epoch = epoch\n",
        "            torch.save(model.state_dict(), 'best_model.pth')  # Save the model checkpoint\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f'Early stopping triggered after {epoch + 1} epochs!')\n",
        "                break\n",
        "\n",
        "    return train_losses, val_losses, val_maes, best_epoch\n",
        "\n",
        "# Train base MLP model\n",
        "train_losses, val_losses, val_maes, best_epoch = train_and_evaluate(\n",
        "    model, train_loader, valid_loader, num_epochs=epoch_num, learning_rate=learning_rate, weight_decay=weight_decay)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu-1c2m0DrL9",
        "outputId": "71fe8123-5622-4bde-d38c-86acef640b7b"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-116-32a97d91d521>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_train = torch.tensor(y_train, dtype=torch.float32)\n",
            "<ipython-input-116-32a97d91d521>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_test = torch.tensor(y_test, dtype=torch.float32)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "Epoch 1/500, Training Loss: 1244264.3955, Validation Loss: 105904.2986\n",
            "Epoch 2/500, Training Loss: 503892.5443, Validation Loss: 32131.9832\n",
            "Epoch 3/500, Training Loss: 272626.6352, Validation Loss: 11488.3293\n",
            "Epoch 4/500, Training Loss: 185279.5847, Validation Loss: 10223.8526\n",
            "Epoch 5/500, Training Loss: 119285.8999, Validation Loss: 7526.2695\n",
            "Epoch 6/500, Training Loss: 109041.9406, Validation Loss: 6576.9689\n",
            "Epoch 7/500, Training Loss: 101298.6197, Validation Loss: 6315.3426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/500, Training Loss: 96324.5909, Validation Loss: 5994.9843\n",
            "Epoch 9/500, Training Loss: 90452.8311, Validation Loss: 5708.6892\n",
            "Epoch 10/500, Training Loss: 87722.4307, Validation Loss: 5186.3786\n",
            "Epoch 11/500, Training Loss: 85524.9821, Validation Loss: 5604.7865\n",
            "Epoch 12/500, Training Loss: 85223.8986, Validation Loss: 5037.9961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/500, Training Loss: 82738.6408, Validation Loss: 4957.7238\n",
            "Epoch 14/500, Training Loss: 81179.7697, Validation Loss: 4670.4965\n",
            "Epoch 15/500, Training Loss: 81674.3887, Validation Loss: 5013.1959\n",
            "Epoch 16/500, Training Loss: 81245.5909, Validation Loss: 4873.1988\n",
            "Epoch 17/500, Training Loss: 81017.7232, Validation Loss: 4816.5351\n",
            "Epoch 18/500, Training Loss: 80500.2700, Validation Loss: 5130.1169\n",
            "Epoch 19/500, Training Loss: 80996.6207, Validation Loss: 4958.9001\n",
            "Early stopping triggered after 19 epochs!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Best epoch: {best_epoch + 1}\")\n",
        "print(f\"Training MSE at best epoch: {train_losses[best_epoch]:.4f}\")\n",
        "print(f\"Validation MSE at best epoch: {val_losses[best_epoch]:.4f}\")\n",
        "print(f\"Validation MAE at best epoch: {val_maes[best_epoch]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVjELwjJUCko",
        "outputId": "3dbc2fb9-e1ce-4cea-a4e0-fad06395d6c4"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best epoch: 14\n",
            "Training MSE at best epoch: 81179.7697\n",
            "Validation MSE at best epoch: 4670.4965\n",
            "Validation MAE at best epoch: 124.4076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "tIX_Z_9aWTWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data standardization\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data to fit LSTM inputs\n",
        "def reshape_for_lstm(X, y, time_steps):\n",
        "    X_reshaped = []\n",
        "    y_reshaped = []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        X_reshaped.append(X[i: i + time_steps])\n",
        "        y_reshaped.append(y[i + time_steps])\n",
        "    return np.array(X_reshaped), np.array(y_reshaped)\n",
        "\n",
        "time_steps = 7  # Time step\n",
        "X_train_reshaped, y_train_reshaped = reshape_for_lstm(X_train, y_train, time_steps)\n",
        "X_test_reshaped, y_test_reshaped = reshape_for_lstm(X_test, y_test, time_steps)\n",
        "\n",
        "# Converted to PyTorch tensor\n",
        "X_train_tensor = torch.tensor(X_train_reshaped, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_reshaped, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_reshaped, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test_reshaped, dtype=torch.float32)\n",
        "\n",
        "# Create the Tensor dataset and DataLoader\n",
        "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
        "valid_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate=0.2):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate)\n",
        "        self.linear = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        out = self.linear(lstm_out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Model parameters\n",
        "input_size = X_train_reshaped.shape[2]  # of features\n",
        "hidden_size = 50  # of LSTM cells\n",
        "num_layers = 3   # of LSTM layers\n",
        "\n",
        "# Initialize the model\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LSTMModel(input_size, hidden_size, num_layers)\n",
        "model.to(device)\n",
        "\n",
        "# Training parameters\n",
        "learning_rate = 0.1\n",
        "weight_decay = 1e-3\n",
        "epoch_num = 500\n",
        "\n",
        "# Define training and evaluation functions\n",
        "def train_and_evaluate(model, train_loader, valid_loader, num_epochs, learning_rate, weight_decay):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Parameters of the early stop method\n",
        "    the_last_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    patience = 5\n",
        "    best_epoch = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        total_val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valid_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                total_val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(valid_loader.dataset)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
        "\n",
        "        if avg_val_loss < the_last_loss:\n",
        "            the_last_loss = avg_val_loss\n",
        "            best_epoch = epoch\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f'Early stopping triggered after {epoch + 1} epochs!')\n",
        "                break\n",
        "\n",
        "    return avg_train_loss, avg_val_loss, best_epoch\n",
        "\n",
        "# Training models\n",
        "train_loss, val_loss, best_epoch = train_and_evaluate(model, train_loader, valid_loader, epoch_num, learning_rate, weight_decay)\n",
        "print(f'Best Epoch: {best_epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdgLItX4Yc6t",
        "outputId": "1e861fe0-c5ad-4d77-cd34-8bab25191e1c"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([49])) that is different to the input size (torch.Size([49, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([42])) that is different to the input size (torch.Size([42, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500, Training Loss: 1299074.4287, Validation Loss: 1246290.1250\n",
            "Epoch 2/500, Training Loss: 1249618.1905, Validation Loss: 1196540.6250\n",
            "Epoch 3/500, Training Loss: 1199842.7139, Validation Loss: 1147459.7500\n",
            "Epoch 4/500, Training Loss: 1151175.9931, Validation Loss: 1099620.6250\n",
            "Epoch 5/500, Training Loss: 1104209.3741, Validation Loss: 1053134.2500\n",
            "Epoch 6/500, Training Loss: 1058185.5208, Validation Loss: 1008322.0625\n",
            "Epoch 7/500, Training Loss: 1013932.4617, Validation Loss: 965005.8750\n",
            "Epoch 8/500, Training Loss: 971131.5827, Validation Loss: 923237.9375\n",
            "Epoch 9/500, Training Loss: 929988.8533, Validation Loss: 882928.5625\n",
            "Epoch 10/500, Training Loss: 890423.3329, Validation Loss: 844017.7500\n",
            "Epoch 11/500, Training Loss: 852138.1633, Validation Loss: 806514.5625\n",
            "Epoch 12/500, Training Loss: 815133.2732, Validation Loss: 770513.6875\n",
            "Epoch 13/500, Training Loss: 779525.6902, Validation Loss: 735930.4375\n",
            "Epoch 14/500, Training Loss: 745621.4489, Validation Loss: 702529.4375\n",
            "Epoch 15/500, Training Loss: 712554.1106, Validation Loss: 670478.2500\n",
            "Epoch 16/500, Training Loss: 681154.6803, Validation Loss: 639533.2500\n",
            "Epoch 17/500, Training Loss: 650647.0147, Validation Loss: 609885.5625\n",
            "Epoch 18/500, Training Loss: 621348.7034, Validation Loss: 581474.8750\n",
            "Epoch 19/500, Training Loss: 593458.5580, Validation Loss: 554127.0000\n",
            "Epoch 20/500, Training Loss: 566392.6796, Validation Loss: 527971.7500\n",
            "Epoch 21/500, Training Loss: 540838.9685, Validation Loss: 502754.7812\n",
            "Epoch 22/500, Training Loss: 516043.3767, Validation Loss: 478674.0625\n",
            "Epoch 23/500, Training Loss: 492423.6665, Validation Loss: 455582.9688\n",
            "Epoch 24/500, Training Loss: 469647.9345, Validation Loss: 433600.2812\n",
            "Epoch 25/500, Training Loss: 447958.3196, Validation Loss: 412587.6250\n",
            "Epoch 26/500, Training Loss: 427273.5882, Validation Loss: 392435.8750\n",
            "Epoch 27/500, Training Loss: 407630.7260, Validation Loss: 373065.7812\n",
            "Epoch 28/500, Training Loss: 388590.1680, Validation Loss: 354664.1250\n",
            "Epoch 29/500, Training Loss: 370414.3461, Validation Loss: 337175.7500\n",
            "Epoch 30/500, Training Loss: 353213.8862, Validation Loss: 320495.3438\n",
            "Epoch 31/500, Training Loss: 336939.8290, Validation Loss: 304513.7812\n",
            "Epoch 32/500, Training Loss: 321167.8971, Validation Loss: 289415.4688\n",
            "Epoch 33/500, Training Loss: 306457.4781, Validation Loss: 274958.1250\n",
            "Epoch 34/500, Training Loss: 292135.9107, Validation Loss: 261339.9688\n",
            "Epoch 35/500, Training Loss: 278687.7338, Validation Loss: 248399.3438\n",
            "Epoch 36/500, Training Loss: 266271.3680, Validation Loss: 235875.5156\n",
            "Epoch 37/500, Training Loss: 253968.8592, Validation Loss: 224154.7188\n",
            "Epoch 38/500, Training Loss: 242549.0599, Validation Loss: 213015.5469\n",
            "Epoch 39/500, Training Loss: 231619.2838, Validation Loss: 202480.5156\n",
            "Epoch 40/500, Training Loss: 221276.1072, Validation Loss: 192525.0781\n",
            "Epoch 41/500, Training Loss: 211456.1634, Validation Loss: 183146.4062\n",
            "Epoch 42/500, Training Loss: 202253.5705, Validation Loss: 174270.2031\n",
            "Epoch 43/500, Training Loss: 193592.2293, Validation Loss: 165856.9219\n",
            "Epoch 44/500, Training Loss: 185327.2087, Validation Loss: 157928.3125\n",
            "Epoch 45/500, Training Loss: 177666.6822, Validation Loss: 150381.6719\n",
            "Epoch 46/500, Training Loss: 170179.8513, Validation Loss: 143399.0000\n",
            "Epoch 47/500, Training Loss: 163462.0856, Validation Loss: 136709.6562\n",
            "Epoch 48/500, Training Loss: 156920.8242, Validation Loss: 130466.4453\n",
            "Epoch 49/500, Training Loss: 150791.0284, Validation Loss: 124637.0625\n",
            "Epoch 50/500, Training Loss: 145228.6902, Validation Loss: 119060.2656\n",
            "Epoch 51/500, Training Loss: 139621.8850, Validation Loss: 113975.1094\n",
            "Epoch 52/500, Training Loss: 134687.6677, Validation Loss: 109148.3516\n",
            "Epoch 53/500, Training Loss: 130007.6317, Validation Loss: 104601.4844\n",
            "Epoch 54/500, Training Loss: 125567.6242, Validation Loss: 100368.0547\n",
            "Epoch 55/500, Training Loss: 121428.1019, Validation Loss: 96419.1719\n",
            "Epoch 56/500, Training Loss: 117513.3289, Validation Loss: 92750.5938\n",
            "Epoch 57/500, Training Loss: 113990.6510, Validation Loss: 89267.8750\n",
            "Epoch 58/500, Training Loss: 110513.7401, Validation Loss: 86064.8125\n",
            "Epoch 59/500, Training Loss: 107420.3134, Validation Loss: 83032.0547\n",
            "Epoch 60/500, Training Loss: 104441.3047, Validation Loss: 80232.5781\n",
            "Epoch 61/500, Training Loss: 101684.5079, Validation Loss: 77631.6641\n",
            "Epoch 62/500, Training Loss: 99196.2536, Validation Loss: 75176.1641\n",
            "Epoch 63/500, Training Loss: 96822.3652, Validation Loss: 72904.0469\n",
            "Epoch 64/500, Training Loss: 94574.6555, Validation Loss: 70828.2891\n",
            "Epoch 65/500, Training Loss: 92581.1164, Validation Loss: 68886.5234\n",
            "Epoch 66/500, Training Loss: 90690.9536, Validation Loss: 67090.4375\n",
            "Epoch 67/500, Training Loss: 88916.1146, Validation Loss: 65455.0469\n",
            "Epoch 68/500, Training Loss: 87309.7777, Validation Loss: 63941.5469\n",
            "Epoch 69/500, Training Loss: 85998.8813, Validation Loss: 62451.0156\n",
            "Epoch 70/500, Training Loss: 84465.9688, Validation Loss: 61176.9648\n",
            "Epoch 71/500, Training Loss: 83200.3126, Validation Loss: 59999.6836\n",
            "Epoch 72/500, Training Loss: 82046.5442, Validation Loss: 58903.7695\n",
            "Epoch 73/500, Training Loss: 80968.7475, Validation Loss: 57897.2656\n",
            "Epoch 74/500, Training Loss: 79987.0803, Validation Loss: 56969.2227\n",
            "Epoch 75/500, Training Loss: 79085.3114, Validation Loss: 56105.3047\n",
            "Epoch 76/500, Training Loss: 78245.4660, Validation Loss: 55310.7852\n",
            "Epoch 77/500, Training Loss: 77488.9922, Validation Loss: 54571.9805\n",
            "Epoch 78/500, Training Loss: 76773.4139, Validation Loss: 53904.0352\n",
            "Epoch 79/500, Training Loss: 76100.7421, Validation Loss: 53306.9102\n",
            "Epoch 80/500, Training Loss: 75520.0260, Validation Loss: 52747.4375\n",
            "Epoch 81/500, Training Loss: 75037.2320, Validation Loss: 52202.4844\n",
            "Epoch 82/500, Training Loss: 74461.0661, Validation Loss: 51761.8398\n",
            "Epoch 83/500, Training Loss: 74022.5541, Validation Loss: 51346.6875\n",
            "Epoch 84/500, Training Loss: 73634.3269, Validation Loss: 50949.1641\n",
            "Epoch 85/500, Training Loss: 73239.6227, Validation Loss: 50603.0312\n",
            "Epoch 86/500, Training Loss: 72942.9195, Validation Loss: 50263.0742\n",
            "Epoch 87/500, Training Loss: 72567.0880, Validation Loss: 49992.6992\n",
            "Epoch 88/500, Training Loss: 72298.4088, Validation Loss: 49732.9531\n",
            "Epoch 89/500, Training Loss: 72041.8637, Validation Loss: 49495.0820\n",
            "Epoch 90/500, Training Loss: 71816.1962, Validation Loss: 49273.4258\n",
            "Epoch 91/500, Training Loss: 71610.1622, Validation Loss: 49065.7812\n",
            "Epoch 92/500, Training Loss: 71402.1675, Validation Loss: 48888.7891\n",
            "Epoch 93/500, Training Loss: 71239.4041, Validation Loss: 48723.2852\n",
            "Epoch 94/500, Training Loss: 71083.5312, Validation Loss: 48572.0117\n",
            "Epoch 95/500, Training Loss: 70934.5264, Validation Loss: 48443.6133\n",
            "Epoch 96/500, Training Loss: 70786.8698, Validation Loss: 48341.4922\n",
            "Epoch 97/500, Training Loss: 70697.3158, Validation Loss: 48230.6172\n",
            "Epoch 98/500, Training Loss: 70595.2730, Validation Loss: 48130.4219\n",
            "Epoch 99/500, Training Loss: 70492.1610, Validation Loss: 48047.8047\n",
            "Epoch 100/500, Training Loss: 70404.9613, Validation Loss: 47976.4336\n",
            "Epoch 101/500, Training Loss: 70340.2421, Validation Loss: 47908.1016\n",
            "Epoch 102/500, Training Loss: 70264.2611, Validation Loss: 47854.1719\n",
            "Epoch 103/500, Training Loss: 70240.4789, Validation Loss: 47786.4258\n",
            "Epoch 104/500, Training Loss: 70153.8475, Validation Loss: 47740.3164\n",
            "Epoch 105/500, Training Loss: 70100.2316, Validation Loss: 47702.6719\n",
            "Epoch 106/500, Training Loss: 70065.7906, Validation Loss: 47661.7227\n",
            "Epoch 107/500, Training Loss: 70042.7691, Validation Loss: 47620.8438\n",
            "Epoch 108/500, Training Loss: 69985.6618, Validation Loss: 47598.0781\n",
            "Epoch 109/500, Training Loss: 69963.7053, Validation Loss: 47573.7266\n",
            "Epoch 110/500, Training Loss: 69942.2198, Validation Loss: 47547.1992\n",
            "Epoch 111/500, Training Loss: 69912.4770, Validation Loss: 47528.2305\n",
            "Epoch 112/500, Training Loss: 69890.1317, Validation Loss: 47511.4727\n",
            "Epoch 113/500, Training Loss: 70163.1193, Validation Loss: 47727.8828\n",
            "Epoch 114/500, Training Loss: 70109.5504, Validation Loss: 47682.3633\n",
            "Epoch 115/500, Training Loss: 70047.0919, Validation Loss: 47652.2188\n",
            "Epoch 116/500, Training Loss: 70015.9050, Validation Loss: 47621.7227\n",
            "Epoch 117/500, Training Loss: 69991.3874, Validation Loss: 47588.7852\n",
            "Early stopping triggered after 117 epochs!\n",
            "Best Epoch: 112, Training Loss: 69991.3874, Validation Loss: 47588.7852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "zieY81s8cUHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Data standardization\n",
        "rf_regressor = RandomForestRegressor(n_estimators=5000, random_state=42)\n",
        "\n",
        "# Training models\n",
        "rf_regressor.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_train = rf_regressor.predict(X_train_scaled)\n",
        "y_pred_test = rf_regressor.predict(X_test_scaled)\n",
        "\n",
        "# Calculate MSE\n",
        "mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "\n",
        "# Calculate MAE\n",
        "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
        "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
        "\n",
        "print(f\"Training MSE: {mse_train}\")\n",
        "print(f\"Test MSE: {mse_test}\")\n",
        "print(f\"Training MAE: {mae_train}\")\n",
        "print(f\"Test MAE: {mae_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENpbghbbcWSu",
        "outputId": "f2029c14-bb89-4259-afc8-5477b97478fd"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MSE: 955.0525179094545\n",
            "Test MSE: 2061.131082118368\n",
            "Training MAE: 17.186164545454545\n",
            "Test MAE: 35.83548163265306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GBM"
      ],
      "metadata": {
        "id": "TxKRhGXveJcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Data standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the gradient lifter regressor\n",
        "gb_regressor = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.01, max_depth=4, random_state=42)\n",
        "\n",
        "# Training models\n",
        "gb_regressor.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make projections\n",
        "y_pred_train = gb_regressor.predict(X_train_scaled)\n",
        "y_pred_test = gb_regressor.predict(X_test_scaled)\n",
        "\n",
        "# Calculate MSE for training and test sets\n",
        "mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "\n",
        "# Calculate MAE\n",
        "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
        "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
        "\n",
        "# Output results\n",
        "print(f\"Training MSE: {mse_train}\")\n",
        "print(f\"Test MSE: {mse_test}\")\n",
        "print(f\"Training MAE: {mae_train}\")\n",
        "print(f\"Test MAE: {mae_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfWP_qIJeMd3",
        "outputId": "95d91ba8-8db4-481c-dd17-5005ef624ec1"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MSE: 462.9060524891934\n",
            "Test MSE: 2018.7942548184033\n",
            "Training MAE: 16.12351207743088\n",
            "Test MAE: 35.13821900636575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN"
      ],
      "metadata": {
        "id": "Crly41xJaNBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "knn = KNeighborsRegressor(n_neighbors=4)\n",
        "\n",
        "\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "y_pred = knn.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "# Calculate MAE\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Test MAE: {mae_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omk_PRqfaPBO",
        "outputId": "01e17175-f5df-4fd2-ae46-5a7585274b0a"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 2562.88134765625\n",
            "Test MAE: 41.382652282714844\n"
          ]
        }
      ]
    }
  ]
}